{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from sbi.analysis import pairplot\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolder = \"0\"\n",
    "data_path = \"91_param_\"\n",
    "# data_path =  \"/p/project/icei-hbp-2021-0002/Jun/91_params_\"\n",
    "mini_batch_size = 125\n",
    "n_sim = 13*125000\n",
    "n_rank = 50\n",
    "os.makedirs(join(data_path, subfolder, \"figs\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_info = json.load(open(join(data_path, \"features_info.json\"), \"r\"))\n",
    "opts = json.load(open(join(data_path, \"opts.json\"), \"r\"))\n",
    "features = list(opts.keys())\n",
    "# features_info#, opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_features(x, threshold=0.001):\n",
    "\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = x.numpy()\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    selector.fit(x)\n",
    "    cols = selector.get_support()\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_features(bold, features, opts):\n",
    "\n",
    "    if bold.ndim == 2:\n",
    "        F = Features(features, opts)\n",
    "        stat_vec, stat_info = F.calc_features(bold)\n",
    "        return stat_vec, stat_info\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def load_stats(rank, i_batch, data_path):\n",
    "    fname = join(data_path, \"stats\", f\"stats_{rank:05d}_{i_batch:05d}.pkl\")\n",
    "    if os.path.exists(fname):\n",
    "        with open(fname, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data['stats'], data['theta']\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def load_stats_all(n_rank, n_batch, mini_batch_size, data_path):\n",
    "\n",
    "    # n_batch = int(np.ceil(n_sim / n_rank/ mini_batch_size))\n",
    "    Theta = []\n",
    "    X = []\n",
    "    for i in range(n_rank):\n",
    "        for j in range(n_batch):\n",
    "            stats_vec, theta_vec = load_stats(i, j, data_path)\n",
    "            if stats_vec is not None:\n",
    "                for k in range(len(theta_vec)):\n",
    "                    if not np.isnan(stats_vec[k]).any():\n",
    "                        Theta.append(theta_vec[k])\n",
    "                        X.append(stats_vec[k])\n",
    "\n",
    "    Theta = np.array(Theta).astype(np.float32)\n",
    "    X = np.array(X).astype(np.float32)\n",
    "    return Theta, X\n",
    "\n",
    "\n",
    "def wrapper_features(x, info, threshold=0.001, prune_dict=None):\n",
    "\n",
    "    flag = False\n",
    "    if prune_dict is None:\n",
    "        flag = True\n",
    "        prune_dict = {}\n",
    "\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.from_numpy(x)\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "\n",
    "    if flag:\n",
    "        prune_dict['all'] = prune_features(x, threshold)\n",
    "    x = x[:, prune_dict['all']].numpy()\n",
    "\n",
    "    return x, prune_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta, x = load_stats_all(50, 260, mini_batch_size, data_path)\n",
    "# print(theta.shape, x.shape, type(theta), type(x), type(theta[0, 0]), type(x[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, prune_dict = wrapper_features(x, features_info)\n",
    "\n",
    "# if isinstance(x_train, np.ndarray):\n",
    "#     x_train = torch.from_numpy(x_train)\n",
    "# if isinstance(theta, np.ndarray):\n",
    "#     theta = torch.from_numpy(theta)\n",
    "\n",
    "# store prune_dict in pickle file\n",
    "# with open(join(data_path, subfolder, \"prune_dict.pkl\"), 'wb') as f:\n",
    "#     pickle.dump(prune_dict, f)\n",
    "\n",
    "prune_dict = pickle.load(open(join(data_path, subfolder, \"prune_dict.pkl\"), 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([838190, 354]), torch.Size([838190, 89]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fcd_sum = slice_x(torch.from_numpy(x), ['fcd_sum'], features_info)\n",
    "# fig, ax = plt.subplots(1, figsize=(6, 4))\n",
    "# ax.plot(theta[:, 0], stats.zscore(fcd_sum[:, 0]), \"r.\", alpha=0.5, ms=1)\n",
    "# ax.set_xlabel(r\"$G$\")\n",
    "# ax.set_ylabel(r\"$\\sum_{i,j} FCD_{i,j}$\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(join(data_path, subfolder, \"figs/fcd_sum.png\"), dpi=300)\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_fcd = np.nanargmax(fcd_sum)\n",
    "# index_fcd, theta[index_fcd, 0]\n",
    "\n",
    "# del x\n",
    "prior = torch.load(join(data_path, \"prior.pt\"))\n",
    "# posterior = train(prior, theta, x_train, n_threads=8)\n",
    "\n",
    "# with open(join(data_path, subfolder, f\"posterior.pickle\"), \"wb\") as cf:\n",
    "#     pickle.dump({\"posterior\": posterior}, cf)\n",
    "posterior = pickle.load(open(join(data_path, subfolder, f\"posterior.pickle\"), \"rb\"))['posterior']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_sim(theta, features, opts):\n",
    "\n",
    "    with open(join(data_path, \"parameters.pkl\"), 'rb') as f:\n",
    "        parameters = pickle.load(f)\n",
    "    parameters['data_path'] = data_path\n",
    "    _, stat_vec, bold = wrapper_simulate(0, parameters, theta, features, opts)\n",
    "    return stat_vec, bold\n",
    "\n",
    "\n",
    "def wrap_i(G_obs, a_obs, b_obs, eta_obs, subname, features, opts, \n",
    "           prune_dict, features_info):\n",
    "    print(f\"simulating bold signal... {subname}\")\n",
    "\n",
    "    if isinstance(eta_obs, np.ndarray):\n",
    "        eta_obs = eta_obs.tolist()\n",
    "    theta_obs = np.array(G_obs + a_obs + b_obs + eta_obs).reshape(1, -1)\n",
    "\n",
    "    stat_obs, bold_obs = wrap_sim(theta_obs.squeeze(), features, opts)\n",
    "    bold_obs.shape, stat_obs.shape\n",
    "    stat_obs_w = wrapper_features(stat_obs, features_info, prune_dict=prune_dict)[0]\n",
    "    posterior = pickle.load(open(join(data_path, subfolder, f\"posterior.pickle\"), \"rb\"))['posterior']\n",
    "    samples = posterior.sample((10000,), x=stat_obs_w)\n",
    "    torch.save(samples, join(data_path, subfolder, f\"samples_{subname}.pt\"))\n",
    "    np.savez(join(data_path, subfolder, f\"bold_{subname}.npz\"),\n",
    "         bold=bold_obs, stat_obs=stat_obs,\n",
    "         theta=theta_obs, stat_obs_w=stat_obs_w)\n",
    "\n",
    "    data = np.load(join(data_path, subfolder, f\"bold_{subname}.npz\"))\n",
    "    theta_obs = data['theta']\n",
    "    samples = torch.load(join(data_path, subfolder, f\"samples_{subname}.pt\"))\n",
    "\n",
    "    plot_triangle(samples, G_obs, a_obs, b_obs, subname)\n",
    "    plot_eta(samples, theta_obs, subname)\n",
    "\n",
    "\n",
    "def plot_triangle(samples, G_obs, a_obs, b_obs, subname):\n",
    "    fig, ax = pairplot(\n",
    "        samples[:, :3],\n",
    "        points=[G_obs + a_obs + b_obs],\n",
    "        figsize=(8, 8),\n",
    "        limits=[[0, 1.1], [0,1], [0,1]],\n",
    "        labels=[\"G\", r\"$\\alpha$\", r\"$\\beta$\"],\n",
    "        upper='kde',\n",
    "        diag='kde',\n",
    "        points_colors=\"r\",\n",
    "        samples_colors=\"k\",\n",
    "        points_offdiag={'markersize': 10})\n",
    "    fig.savefig(join(data_path, subfolder, f\"figs/g_{subname}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_eta(samples, theta_obs, subname):\n",
    "    eta_samples = samples[:, 3:]\n",
    "    eta_true = theta_obs[0, 3:]\n",
    "\n",
    "    _, ax = plt.subplots(1, figsize=(20, 4))\n",
    "    parts = ax.violinplot(eta_samples.T, widths=0.7, showmeans=1, showextrema=1)\n",
    "    ax.plot(np.r_[1:eta_true.shape[0]+1], eta_true, 'o', color='r', alpha=0.9, ms=8)\n",
    "    ax.axhline(y=-4.6, color = 'gray', linestyle = '--', lw=3, alpha=0.5)\n",
    "    ax.set_ylabel(' Posterior ' + r'${(\\eta_i)}$')\n",
    "    ax.set_xlabel('Regions')\n",
    "    ax.tick_params(labelsize=14)\n",
    "\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('green')\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.3)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.margins(x=0.01)\n",
    "    plt.savefig(join(data_path, subfolder, f\"figs/eta_{subname}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = pickle.load(open(join(data_path, \"parameters.pkl\"), \"rb\"))\n",
    "# SC = parameters['adj']\n",
    "# nodes_h = np.argsort(SC.sum(0))[-3:]\n",
    "# nodes_l = np.argsort(SC.sum(0))[:3]\n",
    "\n",
    "# G_obs = [0.6]\n",
    "# a_obs = [0.2]\n",
    "# b_obs = [0.3]\n",
    "# eta_obs = np.array([-4.6]*88)\n",
    "# eta_obs[nodes_h] = -4.0\n",
    "# eta_obs[nodes_l] = -5.5\n",
    "# subname = 5\n",
    "# wrap_i(G_obs, a_obs, b_obs, eta_obs, subname, features, opts, prune_dict, features_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_obs = [0.6]\n",
    "a_obs = [0.2]\n",
    "b_obs = [0.3]\n",
    "eta_obs = np.random.uniform(-6, -3.5, 88)\n",
    "\n",
    "subname=7\n",
    "wrap_i(G_obs, a_obs, b_obs, eta_obs, subname, features, opts, prune_dict, features_info)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
